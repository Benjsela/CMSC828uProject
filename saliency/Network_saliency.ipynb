{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# from flashtorch.utils import apply_transforms, load_image\n",
    "# from flashtorch.saliency import Backprop\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if on a Mac\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = load_image('adorable_puppy.jpg')\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.title('Original image')\n",
    "# plt.axis('off');\n",
    "\n",
    "# noisy = False\n",
    "\n",
    "# if noisy:\n",
    "#     noisy_img = image + np.random.normal(0, 5, (image.size[1],image.size[0], 3))\n",
    "\n",
    "#     # Prepare inputs to be used later\n",
    "\n",
    "#     img = apply_transforms(noisy_img.astype('uint8'))\n",
    "# else:\n",
    "#     img = apply_transforms(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code copied from flashtorch package and modified so that no images are shown\n",
    "class Backprop:\n",
    "    \"\"\"Provides an interface to perform backpropagation.\n",
    "\n",
    "    This class provids a way to calculate the gradients of a target class\n",
    "    output w.r.t. an input image, by performing a single backprobagation.\n",
    "\n",
    "    The gradients obtained can be used to visualise an image-specific class\n",
    "    saliency map, which can gives some intuition on regions within the input\n",
    "    image that contribute the most (and least) to the corresponding output.\n",
    "\n",
    "    More details on saliency maps: `Deep Inside Convolutional Networks:\n",
    "    Visualising Image Classification Models and Saliency Maps\n",
    "    <https://arxiv.org/pdf/1312.6034.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        model: A neural network model from `torchvision.models\n",
    "            <https://pytorch.org/docs/stable/torchvision/models.html>`_.\n",
    "\n",
    "    \"\"\" # noqa\n",
    "\n",
    "    ####################\n",
    "    # Public interface #\n",
    "    ####################\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.gradients = None\n",
    "        self._register_conv_hook()\n",
    "\n",
    "    def calculate_gradients(self,\n",
    "                            input_,\n",
    "                            target_class=None,\n",
    "                            take_max=False,\n",
    "                            guided=False,\n",
    "                            use_gpu=False):\n",
    "\n",
    "        \"\"\"Calculates gradients of the target_class output w.r.t. an input_.\n",
    "\n",
    "        The gradients is calculated for each colour channel. Then, the maximum\n",
    "        gradients across colour channels is returned.\n",
    "\n",
    "        Args:\n",
    "            input_ (torch.Tensor): With shape :math:`(N, C, H, W)`.\n",
    "            target_class (int, optional, default=None)\n",
    "            take_max (bool, optional, default=False): If True, take the maximum\n",
    "                gradients across colour channels for each pixel.\n",
    "            guided (bool, optional, default=Fakse): If True, perform guided\n",
    "                backpropagation. See `Striving for Simplicity: The All\n",
    "                Convolutional Net <https://arxiv.org/pdf/1412.6806.pdf>`_.\n",
    "            use_gpu (bool, optional, default=False): Use GPU if set to True and\n",
    "                `torch.cuda.is_available()`.\n",
    "\n",
    "        Returns:\n",
    "            gradients (torch.Tensor): With shape :math:`(C, H, W)`.\n",
    "\n",
    "        \"\"\" # noqa\n",
    "\n",
    "        if 'inception' in self.model.__class__.__name__.lower():\n",
    "            if input_.size()[1:] != (3, 299, 299):\n",
    "                raise ValueError('Image must be 299x299 for Inception models.')\n",
    "\n",
    "        if guided:\n",
    "            self.relu_outputs = []\n",
    "            self._register_relu_hooks()\n",
    "\n",
    "        if torch.cuda.is_available() and use_gpu:\n",
    "            self.model = self.model.to('cuda')\n",
    "            input_ = input_.to('cuda')\n",
    "\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        self.gradients = torch.zeros(input_.shape)\n",
    "\n",
    "        # Get a raw prediction value (logit) from the last linear layer\n",
    "\n",
    "        output = self.model(input_)\n",
    "\n",
    "        # Don't set the gradient target if the model is a binary classifier\n",
    "        # i.e. has one class prediction\n",
    "\n",
    "        if len(output.shape) == 1:\n",
    "            target = None\n",
    "        else:\n",
    "            _, top_class = output.topk(1, dim=1)\n",
    "\n",
    "            # Create a 2D tensor with shape (1, num_classes) and\n",
    "            # set all element to zero\n",
    "\n",
    "            target = torch.FloatTensor(1, output.shape[-1]).zero_()\n",
    "\n",
    "            if torch.cuda.is_available() and use_gpu:\n",
    "                target = target.to('cuda')\n",
    "\n",
    "#             if (target_class is not None) and (top_class != target_class):\n",
    "#                 warnings.warn(UserWarning(\n",
    "#                     f'The predicted class index {top_class.item()} does not' +\n",
    "#                     f'equal the target class index {target_class}. ' +\n",
    "#                     'Calculating the gradient w.r.t. the predicted class.'\n",
    "#                 ))\n",
    "\n",
    "            # Set the element at top class index to be 1\n",
    "\n",
    "            target[0][top_class] = 1\n",
    "\n",
    "        # Calculate gradients of the target class output w.r.t. input_\n",
    "\n",
    "        output.backward(gradient=target)\n",
    "\n",
    "        # Detach the gradients from the graph and move to cpu\n",
    "\n",
    "        gradients = self.gradients.detach().cpu()[0]\n",
    "\n",
    "        if take_max:\n",
    "            # Take the maximum across colour channels\n",
    "\n",
    "            gradients = gradients.max(dim=0, keepdim=True)[0]\n",
    "\n",
    "        return gradients\n",
    "\n",
    "    def visualize(self, input_, target_class, guided=False, use_gpu=False,\n",
    "                  figsize=(16, 4), cmap='viridis', alpha=.5,\n",
    "                  return_output=False):\n",
    "        \"\"\"Calculates gradients and visualizes the output.\n",
    "\n",
    "        A method that combines the backprop operation and visualization.\n",
    "\n",
    "        It also returns the gradients, if specified with `return_output=True`.\n",
    "\n",
    "        Args:\n",
    "            input_ (torch.Tensor): With shape :math:`(N, C, H, W)`.\n",
    "            target_class (int, optional, default=None)\n",
    "            take_max (bool, optional, default=False): If True, take the maximum\n",
    "                gradients across colour channels for each pixel.\n",
    "            guided (bool, optional, default=Fakse): If True, perform guided\n",
    "                backpropagation. See `Striving for Simplicity: The All\n",
    "                Convolutional Net <https://arxiv.org/pdf/1412.6806.pdf>`_.\n",
    "            use_gpu (bool, optional, default=False): Use GPU if set to True and\n",
    "                `torch.cuda.is_available()`.\n",
    "            figsize (tuple, optional, default=(16, 4)): The size of the plot.\n",
    "            cmap (str, optional, default='viridis): The color map of the\n",
    "                gradients plots. See avaialable color maps `here <https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html>`_.\n",
    "            alpha (float, optional, default=.5): The alpha value of the max\n",
    "                gradients to be jaxaposed on top of the input image.\n",
    "            return_output (bool, optional, default=False): Returns the\n",
    "                output(s) of optimization if set to True.\n",
    "\n",
    "        Returns:\n",
    "            gradients (torch.Tensor): With shape :math:`(C, H, W)`.\n",
    "        \"\"\" # noqa\n",
    "\n",
    "        # Calculate gradients\n",
    "        gradients = self.calculate_gradients(input_,\n",
    "                                             target_class,\n",
    "                                             guided=guided,\n",
    "                                             use_gpu=use_gpu)\n",
    "        max_gradients = self.calculate_gradients(input_,\n",
    "                                                 target_class,\n",
    "                                                 guided=guided,\n",
    "                                                 take_max=True,\n",
    "                                                 use_gpu=use_gpu)\n",
    "\n",
    "        if return_output:\n",
    "            return gradients, max_gradients\n",
    "\n",
    "    #####################\n",
    "    # Private interface #\n",
    "    #####################\n",
    "\n",
    "    def _register_conv_hook(self):\n",
    "        def _record_gradients(module, grad_in, grad_out):\n",
    "            if self.gradients.shape == grad_in[0].shape:\n",
    "                self.gradients = grad_in[0]\n",
    "\n",
    "        for _, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.modules.conv.Conv2d):\n",
    "                module.register_backward_hook(_record_gradients)\n",
    "                break\n",
    "\n",
    "    def _register_relu_hooks(self):\n",
    "        def _record_output(module, input_, output):\n",
    "            self.relu_outputs.append(output)\n",
    "\n",
    "        def _clip_gradients(module, grad_in, grad_out):\n",
    "            relu_output = self.relu_outputs.pop()\n",
    "            clippled_grad_out = grad_out[0].clamp(0.0)\n",
    "\n",
    "            return (clippled_grad_out.mul(relu_output),)\n",
    "\n",
    "        for _, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                module.register_forward_hook(_record_output)\n",
    "                module.register_backward_hook(_clip_gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_helper(model_module, tensor=img, k=84):\n",
    "#     model = model_module(pretrained=True)\n",
    "#     backprop = Backprop(model)\n",
    "#     backprop.visualize(tensor, k, guided=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_helper(models.alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_helper(models.resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_helper_selftrained(model, tensor, k=0):\n",
    "    tensor.requires_grad = True\n",
    "    backprop = Backprop(model)\n",
    "    gradients, max_gradients = backprop.visualize(tensor, k, alpha = 0, return_output = True)\n",
    "    return gradients, max_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../networks')\n",
    "from starter import CNN\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = CNN().to(device)\n",
    "lr = .01\n",
    "momentum = 0.5\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "checkpoint = torch.load(\"../networks/trained_networks/trained_starter\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "model.train()\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader( \n",
    "    datasets.MNIST('../networks/data', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                   ])),\n",
    "        batch_size=1, shuffle=True)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    visualize_helper_selftrained(model, tensor=data, k=target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
